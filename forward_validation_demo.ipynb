{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bd99f68",
   "metadata": {},
   "source": [
    "# Forward Validation Demo\n",
    "## Hybrid Ensemble Model — Premier League 2023–2025\n",
    "\n",
    "This notebook demonstrates **time-aware forward validation** of a hybrid probabilistic football model blending:\n",
    "- **Dixon-Coles** goal-distribution parameters (per-team attack/defence strength)\n",
    "- **LightGBM** gradient boosting on engineered features: xG differential, Elo ratings, recent form, rest days\n",
    "\n",
    "Training is strictly cut off before the evaluation window — no lookahead, no data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd43449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.metrics import accuracy_score, brier_score_loss\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.makedirs('assets', exist_ok=True)\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'figure.facecolor': 'white',\n",
    "    'axes.facecolor': '#f8f9fa',\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.4,\n",
    "    'grid.linestyle': '--',\n",
    "    'font.family': 'sans-serif',\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "})\n",
    "print(\"Libraries loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacd27e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample_dataset.csv')\n",
    "df['match_date'] = pd.to_datetime(df['match_date'])\n",
    "df = df.sort_values('match_date').reset_index(drop=True)\n",
    "\n",
    "# Derive binary target and home-win probability from clean columns\n",
    "df['home_win'] = (df['actual_result'] == 'H').astype(int)\n",
    "df['model_prob_home_win'] = df['prob_H']\n",
    "\n",
    "print(f\"Dataset: {len(df)} matches | {df['match_date'].min().date()} → {df['match_date'].max().date()}\")\n",
    "print(f\"Seasons: {sorted(df['season'].unique())}\")\n",
    "print(f\"\\nSample rows:\")\n",
    "print(df[['match_date','home_team','away_team','actual_result','predicted_result','correct','prob_H','prob_D','prob_A','elo_diff']].head(6).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c079b",
   "metadata": {},
   "source": [
    "## 1. Season Boundary Train / Test Split\n",
    "\n",
    "The model is evaluated using a **hard season boundary split** — training on complete seasons 2021-22 through 2024-25, evaluating on the entire 2025-26 season as a genuinely held-out walk-forward validation.\n",
    "\n",
    "This is the correct unit of separation in football analytics: promotion/relegation reshuffles the team population each summer, meaning a mid-season percentage cut would split newly-promoted sides across train and test. A season boundary avoids that entirely and supports the precise claim: **\"4 complete seasons trained; 2025-26 held out.\"**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33bebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_boundary = pd.Timestamp('2025-08-01')\n",
    "train = df[df['match_date'] < season_boundary].copy()\n",
    "test  = df[df['match_date'] >= season_boundary].copy()\n",
    "split_idx = len(train)  # for chart positioning\n",
    "\n",
    "print(f\"Training : {train['match_date'].min().date()} to {train['match_date'].max().date()}  ({len(train)} matches, 2021-22 → 2024-25)\")\n",
    "print(f\"Test     : {test['match_date'].min().date()} to {test['match_date'].max().date()}   ({len(test)} matches, 2025-26)\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 2.5))\n",
    "ax.barh(y=0, width=len(train), left=0, color='#003366',\n",
    "        label=f'Training — 4 complete seasons ({len(train)} matches)', height=0.6)\n",
    "ax.barh(y=0, width=len(test), left=len(train), color='#E63946',\n",
    "        label=f'Walk-Forward Validation — 2025-26 ({len(test)} matches)', height=0.6)\n",
    "ax.axvline(split_idx, color='white', linewidth=2, linestyle='--')\n",
    "\n",
    "ax.text(split_idx / 2, 0,\n",
    "        f\"Train\\n{train['match_date'].min().date()} to {train['match_date'].max().date()}\",\n",
    "        ha='center', va='center', color='white', fontsize=9, fontweight='bold')\n",
    "ax.text(split_idx + len(test) / 2, 0,\n",
    "        f\"Test\\n{test['match_date'].min().date()} to {test['match_date'].max().date()}\",\n",
    "        ha='center', va='center', color='white', fontsize=9, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Match index (chronological)', fontsize=10)\n",
    "ax.set_title('Forward Validation — Season Boundary Split (2025-26 Held Out Entirely)', fontsize=12, fontweight='bold')\n",
    "ax.legend(loc='upper right', fontsize=9)\n",
    "ax.set_xlim(0, len(df))\n",
    "ax.set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.savefig('assets/forward_validation_split.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f9777",
   "metadata": {},
   "source": [
    "![Forward Validation Split](https://raw.githubusercontent.com/vkenard/football-performance-analytics/main/assets/forward_validation_split.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b030430e",
   "metadata": {},
   "source": [
    "## 2. Performance Metrics on the Test Set\n",
    "\n",
    "Four standard metrics are reported on the held-out test set only:\n",
    "\n",
    "- **3-Way Accuracy** -- fraction of matches where the predicted H/D/A outcome matched reality\n",
    "- **Binary Accuracy** -- home win correctly identified (Yes/No) using a 0.5 probability threshold\n",
    "- **Brier Score** -- mean squared error of probabilities; lower is better (0.0 = perfect)\n",
    "- **Brier Skill Score (BSS)** -- improvement over a naive baseline of always predicting the test-set historical mean win rate; positive confirms the model adds genuine predictive value beyond the base rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c20586",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test['home_win'].values\n",
    "y_prob = test['model_prob_home_win'].values\n",
    "y_pred_binary = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "# 3-way accuracy: use predicted_result column already in the CSV\n",
    "acc_3way   = test['correct'].mean()\n",
    "acc_binary = accuracy_score(y_true, y_pred_binary)\n",
    "\n",
    "# Brier Score vs test-set naive baseline (always predict historical mean)\n",
    "brier          = brier_score_loss(y_true, y_prob)\n",
    "baseline_prob  = np.full(len(y_true), y_true.mean())\n",
    "brier_baseline = brier_score_loss(y_true, baseline_prob)\n",
    "bss            = 1 - (brier / brier_baseline)\n",
    "\n",
    "print(\"=\" * 56)\n",
    "print(\"  FORWARD VALIDATION -- TEST SET RESULTS\")\n",
    "print(\"=\" * 56)\n",
    "print(f\"  {'Test set home win rate':<38} {y_true.mean():.3f}\")\n",
    "print(f\"  {'3-Way Match Accuracy (H/D/A)':<38} {acc_3way:.3f}\")\n",
    "print(f\"  {'Binary Accuracy (Home Win, t=0.5)':<38} {acc_binary:.3f}\")\n",
    "print(f\"  {'Brier Score (model)':<38} {brier:.4f}\")\n",
    "print(f\"  {'Brier Score (naive baseline)':<38} {brier_baseline:.4f}\")\n",
    "print(f\"  {'Brier Skill Score':<38} {bss:+.4f}  ({'beats naive baseline' if bss > 0 else 'below naive baseline'})\")\n",
    "print(\"=\" * 56)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4eb13c",
   "metadata": {},
   "source": [
    "## 3. Rolling Performance Drift Detection\n",
    "\n",
    "A **20-match rolling Brier score** is tracked across the full dataset to identify periods of performance drift.  \n",
    "Rising values indicate the model is struggling — often coinciding with squad changes, managerial turnover, or shifting tactical profiles mid-season.  \n",
    "This kind of longitudinal monitoring is directly applicable to academy development tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39759055",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 20\n",
    "y_all  = df['home_win'].values\n",
    "p_all  = df['model_prob_home_win'].values\n",
    "\n",
    "rolling_brier = [\n",
    "    np.mean((y_all[i:i+window] - p_all[i:i+window]) ** 2)\n",
    "    for i in range(len(df) - window + 1)\n",
    "]\n",
    "rolling_dates = df['match_date'].iloc[window - 1:].reset_index(drop=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13, 4.5))\n",
    "ax.plot(rolling_dates, rolling_brier, color='#003366', linewidth=1.8,\n",
    "        label=f'Rolling Brier ({window}-match window)')\n",
    "ax.axhline(brier, color='#E63946', linewidth=1.5, linestyle='--',\n",
    "           label=f'Overall test Brier = {brier:.4f}')\n",
    "ax.axhline(0.25, color='#888888', linewidth=1.2, linestyle=':',\n",
    "           label='Coin-flip reference (0.25)')\n",
    "ax.axvline(pd.Timestamp(split_date), color='#2a9d8f', linewidth=1.8, linestyle='--',\n",
    "           label=f'Train / Test split ({split_date})')\n",
    "\n",
    "ax.fill_between(rolling_dates, rolling_brier, 0.25,\n",
    "                where=[v < 0.25 for v in rolling_brier],\n",
    "                alpha=0.12, color='#003366', interpolate=True, label='Better than coin-flip')\n",
    "ax.fill_between(rolling_dates, rolling_brier, 0.25,\n",
    "                where=[v >= 0.25 for v in rolling_brier],\n",
    "                alpha=0.12, color='#E63946', interpolate=True, label='Worse than coin-flip')\n",
    "\n",
    "ax.set_ylim(0.10, 0.35)\n",
    "ax.set_xlabel('Match Date', fontsize=11)\n",
    "ax.set_ylabel('Rolling Brier Score', fontsize=11)\n",
    "ax.set_title('Rolling Brier Score -- Performance Drift Detection\\n(Lower = More Accurate Probability Estimates)',\n",
    "             fontsize=12, fontweight='bold')\n",
    "ax.legend(fontsize=9, loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('assets/drift_monitoring.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Charts saved to assets/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eff4c88",
   "metadata": {},
   "source": [
    "![Drift Monitoring](https://raw.githubusercontent.com/vkenard/football-performance-analytics/main/assets/drift_monitoring.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce48abdd",
   "metadata": {},
   "source": [
    "## 4. Feature Importance -- What is Driving the Predictions?\n",
    "\n",
    "Understanding *why* the model produces a particular probability is as important as the probability itself. This matters directly for coaching and academy staff: if rest days are a top driver, that informs scheduling decisions; if xG differential is dominant, it validates the use of expected goals as a development metric.\n",
    "\n",
    "A Random Forest is fitted to the 8 engineered input features (excluding the probability outputs) to quantify which features contribute most to predicting home win outcomes. Feature importance is measured by mean decrease in impurity across all trees.\n",
    "\n",
    "> **Note:** The Dixon-Coles and LightGBM blend already encodes most of this signal in `prob_H`. The chart below shows the *raw feature signal* independently -- useful for confirming which inputs the ensemble is actually relying on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c21875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "feature_cols = ['elo_diff', 'xg_diff', 'dc_home_attack', 'dc_away_defence',\n",
    "                'form_home_5', 'form_away_5', 'rest_days_home', 'rest_days_away']\n",
    "feature_labels = {\n",
    "    'elo_diff':         'Elo Rating Gap',\n",
    "    'xg_diff':          'xG Differential',\n",
    "    'dc_home_attack':   'DC Home Attack',\n",
    "    'dc_away_defence':  'DC Away Defence',\n",
    "    'form_home_5':      'Home Form (5 games)',\n",
    "    'form_away_5':      'Away Form (5 games)',\n",
    "    'rest_days_home':   'Home Rest Days',\n",
    "    'rest_days_away':   'Away Rest Days',\n",
    "}\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df['home_win'].values\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=300, max_depth=5, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "importances = (\n",
    "    pd.Series(rf.feature_importances_, index=feature_cols)\n",
    "    .rename(index=feature_labels)\n",
    "    .sort_values()\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "colors = ['#003366' if v >= importances.median() else '#6c9ec8' for v in importances.values]\n",
    "bars = ax.barh(importances.index, importances.values, color=colors, edgecolor='none')\n",
    "\n",
    "for bar, val in zip(bars, importances.values):\n",
    "    ax.text(val + 0.002, bar.get_y() + bar.get_height() / 2,\n",
    "            f'{val:.3f}', va='center', fontsize=9)\n",
    "\n",
    "ax.set_xlabel('Feature Importance (Mean Decrease in Impurity)', fontsize=10)\n",
    "ax.set_title('Feature Importance -- Drivers of Home Win Prediction\\n(Random Forest, 300 trees, full 348-match sample)',\n",
    "             fontsize=11, fontweight='bold')\n",
    "ax.set_xlim(0, importances.max() * 1.2)\n",
    "plt.tight_layout()\n",
    "plt.savefig('assets/feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: assets/feature_importance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0415cb6",
   "metadata": {},
   "source": [
    "![Feature Importance](https://raw.githubusercontent.com/vkenard/football-performance-analytics/main/assets/feature_importance.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
